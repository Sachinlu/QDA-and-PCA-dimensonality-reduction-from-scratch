{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "FU15HDQtfYoM",
   "metadata": {
    "id": "FU15HDQtfYoM"
   },
   "source": [
    "##INSTRUCTION:\n",
    "\n",
    "\n",
    "1.   This program is trained and tested on the GPU environment. Plese make sure that your colab notebook is connected to GPU Runtime.\n",
    "2.  The main aim of the below network is to observe the major differences between training from scratch and Transfer Learning (using Pre-trained weights).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ujrW9-SwmndB",
   "metadata": {
    "id": "ujrW9-SwmndB"
   },
   "source": [
    "Importing All Important Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dGQX7P5ORh44",
   "metadata": {
    "id": "dGQX7P5ORh44"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tensorflow.keras.applications import DenseNet169\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.initializers import he_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WNqZAHPonTaP",
   "metadata": {
    "id": "WNqZAHPonTaP"
   },
   "source": [
    "Importing Time to compare the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "JlsIWhZvaqkR",
   "metadata": {
    "id": "JlsIWhZvaqkR"
   },
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0XT3p9vOnWpb",
   "metadata": {
    "id": "0XT3p9vOnWpb"
   },
   "source": [
    "Data was dowloaded on the local file. Please specify your specific path or used the data submitted along with this code file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fO8LwL3q4XoX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fO8LwL3q4XoX",
    "outputId": "2b46fa4e-32b4-4d85-a15a-e86403a8e85c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R7Y-TaRHplOK",
   "metadata": {
    "id": "R7Y-TaRHplOK"
   },
   "source": [
    "Loading data, Converting images into RGB, Scalling, Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98bf08ec",
   "metadata": {
    "id": "98bf08ec"
   },
   "outputs": [],
   "source": [
    "def generator(dir, gen = image.ImageDataGenerator(rescale = 1./255), shuffle = True,\n",
    "            batch_size = 1, target_size=(24, 24), class_mode = 'categorical'):\n",
    "    return gen.flow_from_directory(dir,batch_size=batch_size, shuffle=shuffle, color_mode='rgb',\n",
    "                                   class_mode=class_mode, target_size=target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nsJpF3-zp5w1",
   "metadata": {
    "id": "nsJpF3-zp5w1"
   },
   "source": [
    "Defining Batch Size and Target Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb654cc",
   "metadata": {
    "id": "cdb654cc"
   },
   "outputs": [],
   "source": [
    "BS = 32\n",
    "TS = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EFGpVYW6p_do",
   "metadata": {
    "id": "EFGpVYW6p_do"
   },
   "source": [
    "**Scene-15 dataset** \n",
    "\n",
    "Loading Data into Train and Validate batch.\n",
    "\n",
    "> total no of classes = 15\n",
    "\n",
    "> total no of images = 4485\n",
    "\n",
    "Assignment 4 requirements \n",
    "\n",
    "> Randomly selecting 100 images per class (15 X 100) = 1500 images for training.\n",
    "\n",
    "> Remaining images are used for testing (4485 - 1500) = 2985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38631469",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38631469",
    "outputId": "4d30586c-71eb-489d-b6eb-72755294508c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 15 classes.\n",
      "Found 2985 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batch = generator('/content/drive/MyDrive/15-Scene/train', shuffle=True, batch_size = BS, target_size = TS)\n",
    "valid_batch = generator('/content/drive/MyDrive/15-Scene/test', shuffle=True, batch_size = BS, target_size = TS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6WJeE9ysIJm",
   "metadata": {
    "id": "a6WJeE9ysIJm"
   },
   "source": [
    "Defining Input Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00Boy8nEa8R4",
   "metadata": {
    "id": "00Boy8nEa8R4"
   },
   "outputs": [],
   "source": [
    "initial = he_normal()\n",
    "input_shape_densenet = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L5M7ZEtesTSj",
   "metadata": {
    "id": "L5M7ZEtesTSj"
   },
   "source": [
    "Creating Model object with Weights None. (Training from Scratch).\n",
    "\n",
    "> When weights None. (Training from Scratch).\n",
    "\n",
    "> When weights = 'imagnet' (pre-trained weights, Transfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ttQigT3yM3iz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ttQigT3yM3iz",
    "outputId": "92607bec-a8f4-4ea1-ef0d-5c6dca911e38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "51879936/51877672 [==============================] - 1s 0us/step\n",
      "51888128/51877672 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "densenet_model = DenseNet169(\n",
    "    include_top=False,\n",
    "    weights= \"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape_densenet,\n",
    "    pooling=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66F6FLr-O-3-",
   "metadata": {
    "id": "66F6FLr-O-3-"
   },
   "outputs": [],
   "source": [
    "# uncomment to see the training from scratch\n",
    "# densenet_model = DenseNet169(\n",
    "#     include_top=False,\n",
    "#     weights= None,\n",
    "#     input_tensor=None,\n",
    "#     input_shape=input_shape_densenet,\n",
    "#     pooling=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "XH3-0iG4NPDE",
   "metadata": {
    "id": "XH3-0iG4NPDE"
   },
   "outputs": [],
   "source": [
    "densenet_model.trainable = True\n",
    "for layer in densenet_model.layers:\n",
    "  if 'conv5' in layer.name:\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9wnQaBebGZ3",
   "metadata": {
    "id": "a9wnQaBebGZ3"
   },
   "outputs": [],
   "source": [
    "# uncomment to see the training from scratch\n",
    "# densenet_model.trainable = True\n",
    "# for layer in densenet_model.layers:\n",
    "#   if 'conv5' in layer.name:\n",
    "#     layer.trainable = True\n",
    "#   else:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "uvfa9NGebUAD",
   "metadata": {
    "id": "uvfa9NGebUAD"
   },
   "outputs": [],
   "source": [
    "input = Input(input_shape_densenet)\n",
    "new_layer = densenet_model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tkvE3UWgspu6",
   "metadata": {
    "id": "tkvE3UWgspu6"
   },
   "source": [
    "Flatining the layer and adding FC layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8X_-VVDYbo9Y",
   "metadata": {
    "id": "8X_-VVDYbo9Y"
   },
   "outputs": [],
   "source": [
    "new_layer = Flatten()(new_layer)\n",
    "\n",
    "new_layer = BatchNormalization()(new_layer)\n",
    "\n",
    "new_layer = Dense(units=256, activation='relu', kernel_initializer= initial)(new_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "w2IFLDZQborW",
   "metadata": {
    "id": "w2IFLDZQborW"
   },
   "outputs": [],
   "source": [
    "new_layer = Dropout(0.4)(new_layer)\n",
    "\n",
    "new_layer = BatchNormalization()(new_layer)\n",
    "\n",
    "new_layer = Dense(units=128, activation='relu', kernel_initializer= initial)(new_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-vTMCF2Ys1Ic",
   "metadata": {
    "id": "-vTMCF2Ys1Ic"
   },
   "source": [
    "Output layer with Softmax Activation funaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ZqvqiepbceC",
   "metadata": {
    "id": "8ZqvqiepbceC"
   },
   "outputs": [],
   "source": [
    "new_layer = Dropout(0.4)(new_layer)\n",
    "\n",
    "output = Dense(units=15, activation='softmax', kernel_initializer= initial)(new_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CDohNkD8s8br",
   "metadata": {
    "id": "CDohNkD8s8br"
   },
   "source": [
    "Printing Model Summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "FmgFyxs9cRPA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FmgFyxs9cRPA",
    "outputId": "59144dd3-ff60-4608-d7fa-40660cecd744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " densenet169 (Functional)    (None, 7, 7, 1664)        12642880  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 81536)             0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 81536)            326144    \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               20873472  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 15)                1935      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,878,351\n",
      "Trainable params: 26,985,487\n",
      "Non-trainable params: 6,892,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "densenet_model = Model(inputs=input, outputs=output)\n",
    "densenet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-M9fT-7ZtCXA",
   "metadata": {
    "id": "-M9fT-7ZtCXA"
   },
   "source": [
    "Compiling the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "R0I6aLiDdAhj",
   "metadata": {
    "id": "R0I6aLiDdAhj"
   },
   "outputs": [],
   "source": [
    "densenet_model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xVidqWfhtIw4",
   "metadata": {
    "id": "xVidqWfhtIw4"
   },
   "source": [
    "Fitting the model.\n",
    "\n",
    "This is for training from scratch single Run with 40 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0enbwf6mdJau",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0enbwf6mdJau",
    "outputId": "94d746ed-eba3-4d61-c23f-361e7c478e41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "47/47 [==============================] - 788s 16s/step - loss: 0.5110 - accuracy: 0.0953 - val_loss: 0.2656 - val_accuracy: 0.0553\n",
      "Epoch 2/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.2770 - accuracy: 0.1807 - val_loss: 0.2568 - val_accuracy: 0.0881\n",
      "Epoch 3/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.2306 - accuracy: 0.2987 - val_loss: 0.2626 - val_accuracy: 0.1233\n",
      "Epoch 4/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.2052 - accuracy: 0.3893 - val_loss: 0.3721 - val_accuracy: 0.0727\n",
      "Epoch 5/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.1854 - accuracy: 0.4260 - val_loss: 0.4008 - val_accuracy: 0.0687\n",
      "Epoch 6/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.1645 - accuracy: 0.5073 - val_loss: 0.3321 - val_accuracy: 0.1069\n",
      "Epoch 7/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.1456 - accuracy: 0.5593 - val_loss: 0.4147 - val_accuracy: 0.1826\n",
      "Epoch 8/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.1292 - accuracy: 0.6300 - val_loss: 0.2951 - val_accuracy: 0.1963\n",
      "Epoch 9/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.1104 - accuracy: 0.6873 - val_loss: 0.3283 - val_accuracy: 0.2037\n",
      "Epoch 10/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0992 - accuracy: 0.7280 - val_loss: 0.3425 - val_accuracy: 0.2235\n",
      "Epoch 11/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0860 - accuracy: 0.7720 - val_loss: 0.3080 - val_accuracy: 0.2345\n",
      "Epoch 12/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0767 - accuracy: 0.8013 - val_loss: 0.2300 - val_accuracy: 0.3447\n",
      "Epoch 13/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0728 - accuracy: 0.8147 - val_loss: 0.3076 - val_accuracy: 0.2894\n",
      "Epoch 14/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0594 - accuracy: 0.8720 - val_loss: 0.2352 - val_accuracy: 0.4054\n",
      "Epoch 15/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0500 - accuracy: 0.8940 - val_loss: 0.4048 - val_accuracy: 0.2302\n",
      "Epoch 16/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0423 - accuracy: 0.9160 - val_loss: 0.3637 - val_accuracy: 0.2268\n",
      "Epoch 17/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0376 - accuracy: 0.9300 - val_loss: 0.3994 - val_accuracy: 0.2358\n",
      "Epoch 18/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0405 - accuracy: 0.9100 - val_loss: 0.4574 - val_accuracy: 0.2506\n",
      "Epoch 19/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0348 - accuracy: 0.9280 - val_loss: 0.3144 - val_accuracy: 0.2419\n",
      "Epoch 20/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0245 - accuracy: 0.9560 - val_loss: 0.3588 - val_accuracy: 0.2951\n",
      "Epoch 21/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0234 - accuracy: 0.9593 - val_loss: 0.2203 - val_accuracy: 0.4794\n",
      "Epoch 22/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0210 - accuracy: 0.9693 - val_loss: 0.2738 - val_accuracy: 0.4338\n",
      "Epoch 23/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0217 - accuracy: 0.9653 - val_loss: 0.2767 - val_accuracy: 0.4231\n",
      "Epoch 24/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0235 - accuracy: 0.9580 - val_loss: 0.4913 - val_accuracy: 0.1792\n",
      "Epoch 25/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0227 - accuracy: 0.9540 - val_loss: 0.3204 - val_accuracy: 0.3725\n",
      "Epoch 26/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0215 - accuracy: 0.9647 - val_loss: 0.5907 - val_accuracy: 0.2023\n",
      "Epoch 27/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0168 - accuracy: 0.9693 - val_loss: 0.3117 - val_accuracy: 0.4268\n",
      "Epoch 28/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0167 - accuracy: 0.9653 - val_loss: 0.4130 - val_accuracy: 0.3293\n",
      "Epoch 29/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0119 - accuracy: 0.9860 - val_loss: 0.4082 - val_accuracy: 0.3595\n",
      "Epoch 30/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0121 - accuracy: 0.9793 - val_loss: 0.4962 - val_accuracy: 0.2020\n",
      "Epoch 31/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0193 - accuracy: 0.9667 - val_loss: 0.4906 - val_accuracy: 0.2332\n",
      "Epoch 32/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0141 - accuracy: 0.9787 - val_loss: 0.5680 - val_accuracy: 0.2489\n",
      "Epoch 33/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0162 - accuracy: 0.9640 - val_loss: 0.4603 - val_accuracy: 0.2884\n",
      "Epoch 34/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0125 - accuracy: 0.9793 - val_loss: 0.4860 - val_accuracy: 0.2328\n",
      "Epoch 35/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0132 - accuracy: 0.9773 - val_loss: 0.4922 - val_accuracy: 0.3106\n",
      "Epoch 36/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0137 - accuracy: 0.9733 - val_loss: 0.2970 - val_accuracy: 0.4462\n",
      "Epoch 37/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0168 - accuracy: 0.9673 - val_loss: 0.6104 - val_accuracy: 0.2302\n",
      "Epoch 38/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0122 - accuracy: 0.9767 - val_loss: 0.5458 - val_accuracy: 0.3002\n",
      "Epoch 39/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0114 - accuracy: 0.9820 - val_loss: 0.4491 - val_accuracy: 0.3156\n",
      "Epoch 40/40\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.0093 - accuracy: 0.9853 - val_loss: 0.1882 - val_accuracy: 0.6013\n"
     ]
    }
   ],
   "source": [
    "previous = densenet_model.fit(train_batch, validation_data=valid_batch, epochs=40, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bB61MEX9OB7T",
   "metadata": {
    "id": "bB61MEX9OB7T"
   },
   "source": [
    "This is for Training from Pretarined\n",
    "running 3 times and taking average accuracy for each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48uxT6m8OBd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48uxT6m8OBd4",
    "outputId": "5e3a6314-2892-409f-9c64-e3d856d1a667"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is 1 Run for 6 epochs\n",
      "Epoch 1/6\n",
      "47/47 [==============================] - 777s 16s/step - loss: 0.3914 - accuracy: 0.3547 - val_loss: 0.2173 - val_accuracy: 0.5059\n",
      "Epoch 2/6\n",
      "47/47 [==============================] - 41s 886ms/step - loss: 0.1080 - accuracy: 0.7760 - val_loss: 0.0950 - val_accuracy: 0.7481\n",
      "Epoch 3/6\n",
      "47/47 [==============================] - 41s 887ms/step - loss: 0.0645 - accuracy: 0.8980 - val_loss: 0.0555 - val_accuracy: 0.8590\n",
      "Epoch 4/6\n",
      "47/47 [==============================] - 41s 886ms/step - loss: 0.0423 - accuracy: 0.9347 - val_loss: 0.0506 - val_accuracy: 0.8707\n",
      "Epoch 5/6\n",
      "47/47 [==============================] - 41s 885ms/step - loss: 0.0292 - accuracy: 0.9640 - val_loss: 0.0431 - val_accuracy: 0.8911\n",
      "Epoch 6/6\n",
      "47/47 [==============================] - 41s 886ms/step - loss: 0.0212 - accuracy: 0.9747 - val_loss: 0.0443 - val_accuracy: 0.8827\n",
      "This is 2 Run for 6 epochs\n",
      "Epoch 1/6\n",
      "47/47 [==============================] - 41s 889ms/step - loss: 0.0164 - accuracy: 0.9813 - val_loss: 0.0465 - val_accuracy: 0.8844\n",
      "Epoch 2/6\n",
      "47/47 [==============================] - 41s 886ms/step - loss: 0.0152 - accuracy: 0.9867 - val_loss: 0.0576 - val_accuracy: 0.8492\n",
      "Epoch 3/6\n",
      "47/47 [==============================] - 41s 885ms/step - loss: 0.0118 - accuracy: 0.9867 - val_loss: 0.0480 - val_accuracy: 0.8801\n",
      "Epoch 4/6\n",
      "47/47 [==============================] - 41s 886ms/step - loss: 0.0081 - accuracy: 0.9900 - val_loss: 0.0433 - val_accuracy: 0.8938\n",
      "Epoch 5/6\n",
      "47/47 [==============================] - 41s 888ms/step - loss: 0.0079 - accuracy: 0.9927 - val_loss: 0.0581 - val_accuracy: 0.8707\n",
      "Epoch 6/6\n",
      "47/47 [==============================] - 41s 888ms/step - loss: 0.0066 - accuracy: 0.9900 - val_loss: 0.0482 - val_accuracy: 0.8945\n",
      "This is 3 Run for 6 epochs\n",
      "Epoch 1/6\n",
      "47/47 [==============================] - 41s 889ms/step - loss: 0.0065 - accuracy: 0.9927 - val_loss: 0.0597 - val_accuracy: 0.8663\n",
      "Epoch 2/6\n",
      "47/47 [==============================] - 41s 888ms/step - loss: 0.0055 - accuracy: 0.9960 - val_loss: 0.0456 - val_accuracy: 0.8958\n",
      "Epoch 3/6\n",
      "47/47 [==============================] - 41s 889ms/step - loss: 0.0050 - accuracy: 0.9953 - val_loss: 0.0777 - val_accuracy: 0.8513\n",
      "Epoch 4/6\n",
      "47/47 [==============================] - 41s 885ms/step - loss: 0.0065 - accuracy: 0.9933 - val_loss: 0.0558 - val_accuracy: 0.8804\n",
      "Epoch 5/6\n",
      "47/47 [==============================] - 41s 885ms/step - loss: 0.0067 - accuracy: 0.9893 - val_loss: 0.0515 - val_accuracy: 0.8918\n",
      "Epoch 6/6\n",
      "47/47 [==============================] - 41s 885ms/step - loss: 0.0069 - accuracy: 0.9887 - val_loss: 0.0505 - val_accuracy: 0.8982\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 4):\n",
    "  print(f\"This is {i} Run for 6 epochs\")\n",
    "  version = densenet_model.fit(train_batch, validation_data=valid_batch, epochs=6, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DenseNet_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
